# 3.1 Optimization: Partitioning and Clustering

**[↑ Up](README.md)** | **[← Previous](README.md)** | **[Next →](3.2-bqml-training.md)**

---

**Folder Structure:**
```
project/
├── 3.1-optimization.md  <-- You are here
├── 3.2-bqml-training.md
├── 3.3-export-serving.md
└── 3.4-prediction-test.md
```

## Objective

We will create an optimized table `yellow_tripdata_optimized` in BigQuery to improve query performance and reduce costs. We will use **Partitioning** and **Clustering** strategies based on our analysis of the dataset access patterns.

## Data Engineering: Creating the Optimized Table

The goal is to transform the raw taxi data into a highly efficient format.

### Step 1: Access BigQuery Console

1.  Open your web browser and navigate to the **[Google Cloud Console](https://console.cloud.google.com/)**.
2.  In the top navigation bar, ensure your **Project** is selected (e.g., `ny-taxi-project`).
3.  In the **Search** bar at the top, type `BigQuery` and press Enter.
4.  Click on **BigQuery** in the search results. This will open the BigQuery Studio interface.

### Step 2: Prepare the Environment

1.  On the left side, you will see the **Explorer** pane. This shows your projects and datasets.
2.  Click on the **three dots** (⋮) next to your project ID in the Explorer pane.
3.  Select **Create dataset**.
4.  **Dataset ID**: Enter a name, for example: `trips_data_all`.
5.  **Location type**: Select **Region**.
6.  **Region**: Choose `us-central1` (or your preferred region).
7.  Click **Create dataset**.

### Step 3: Run the Optimization SQL

1.  In the center of the screen, you will see the **Editor** tab (a large white text area). If not open, click the **+ COMPOSE NEW QUERY** button.
2.  Copy and paste the following SQL code into the Editor.
3.  **Crucial**: Replace `your_project.your_dataset` with your actual Project ID and Dataset Name (e.g., `ny-taxi-project.trips_data_all`).

```sql
CREATE OR REPLACE TABLE `your_project.your_dataset.yellow_tripdata_optimized`
PARTITION BY DATE(tpep_pickup_datetime)
CLUSTER BY PULocationID, payment_type
AS
SELECT
  VendorID,
  tpep_pickup_datetime,
  tpep_dropoff_datetime,
  passenger_count,
  trip_distance,
  RatecodeID,
  store_and_fwd_flag,
  PULocationID,
  DOLocationID,
  payment_type,
  fare_amount,
  extra,
  mta_tax,
  tip_amount,
  tolls_amount,
  improvement_surcharge,
  total_amount,
  congestion_surcharge
FROM
  `bigquery-public-data.new_york_taxi_trips.tlc_yellow_trips_2021`
WHERE
    -- Ensure we only pick up valid dates for the partition range
    DATE(tpep_pickup_datetime) BETWEEN '2021-01-01' AND '2021-12-31';
```

4.  Look at the top-right corner of the Editor window. You should see a green checkmark string saying something like **"This query will process 2.8 GB when run."**
5.  Click the blue **RUN** button.

**Explanation of the Code:**

*   **`PARTITION BY DATE(tpep_pickup_datetime)`**: We partition by the pickup date (daily) because our queries mostly filter by date ranges (e.g., "How many trips happened on Jan 1st?"). This allows BigQuery to prune partitions and scan less data.
*   **`CLUSTER BY PULocationID, payment_type`**: Within each partition, we sort data by Location ID and Payment Type. This improves performance for queries that filter or aggregate by these specific columns (e.g., "Average tip by location").
*   **`AS SELECT ...`**: We populate the table immediately from the public dataset. We explicitly select columns to ensure schema control.

> **Warning**
>
> Running this query will process approximately **2-3 GB** of data. Ensure you have the necessary quota and permissions in your Google Cloud project.

## Verification

After the query finishes (it should take about 30-60 seconds):

1.  Go back to the **Explorer** pane on the left.
2.  Expand your dataset (`trips_data_all`).
3.  Click on the newly created table `yellow_tripdata_optimized`.
4.  Click on the **Details** tab in the main window.
5.  Verify the following:
    *   **Table Size**: ~2-3 GB.
    *   **Partitioned by**: Day.
    *   **Clustered by**: `PULocationID`, `payment_type`.
